{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bagging_and_random_forest_coursera.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUJBsXeBWya4riWX8FNCt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upayuryeva/ML-and-DA-coursera/blob/main/Bagging_and_random_forest_coursera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzpLNPoyqrP"
      },
      "source": [
        "#Bagging and random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxj8Zw0GxrqN"
      },
      "source": [
        "from sklearn import model_selection, datasets, metrics, tree \n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElzG0uxey4mv"
      },
      "source": [
        "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "050F0c4ozUM1"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "X, y = load_digits(return_X_y=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKiT-zTAyoiJ"
      },
      "source": [
        "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.model_selection с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
        "\n",
        "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадет в диапазон, заданный для правильных ответов - в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
        "\n",
        "Если вам захочется ускорить вычисление cross_val_score - можете попробовать использовать параметр n_jobs, но будьте осторожны: в одной из старых версий sklearn была ошибка, которая приводила к неверному результату работы cross_val_score при задании n_jobs отличным от 1. Сейчас такой проблемы возникнуть не должно, но проверить, что все в порядке, не будет лишним.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93X6gntayoFP"
      },
      "source": [
        "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эта величина и будет ответом в пункте 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH3QELlv0ekP"
      },
      "source": [
        "def write_answer(clf, num):\n",
        "  answ = cross_val_score(clf, X, y, cv=10).mean()\n",
        "\n",
        "  print(answ)\n",
        "\n",
        "  with open(\"answer%d.txt\" % num , \"w\") as fout:\n",
        "          fout.write(str(answ))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTHADTxg1M3n",
        "outputId": "aebb29e3-be1c-4a49-daa5-4ecf239fa6db"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "decision_tree_clf = tree.DecisionTreeClassifier(random_state=1)\n",
        "write_answer(decision_tree_clf, 1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8241154562383614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bab19FRp36hx"
      },
      "source": [
        "Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100. \n",
        "\n",
        "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOWgaLMA1ZnA",
        "outputId": "4577bf60-719c-4d25-c008-955992361358"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "bagging_clf = BaggingClassifier(n_estimators=100)\n",
        "write_answer(bagging_clf, 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9214990689013035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfouGDoB5x6p"
      },
      "source": [
        "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на $\\sqrt{d}$ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWwxTfqo5SUI",
        "outputId": "02c57da4-2f0c-4053-a81d-8135a1965b52"
      },
      "source": [
        "bagging_clf_2 = BaggingClassifier(n_estimators=100, max_features=np.sqrt(X.shape[1])/X.shape[1])\n",
        "write_answer(bagging_clf_2, 3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9321042830540037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0PMZHq-L3J"
      },
      "source": [
        "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же  $\\sqrt{d}$ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhtLTiTq8iVq",
        "outputId": "b8bfc7b7-8b2c-4e41-b005-c49ea924ecaf"
      },
      "source": [
        "decision_tree_clf_2 = tree.DecisionTreeClassifier(max_features=np.sqrt(X.shape[1])/X.shape[1], random_state=1)\n",
        "bagging_clf_3 = BaggingClassifier(decision_tree_clf_2, n_estimators=100)\n",
        "\n",
        "# for _ in range(10):\n",
        "#   print(cross_val_score(bagging_clf_3, X, y, cv=10).mean())\n",
        "\n",
        "write_answer(bagging_clf_3, 4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9493637492240843\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}